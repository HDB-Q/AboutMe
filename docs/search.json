[
  {
    "objectID": "projects.html#project-2",
    "href": "projects.html#project-2",
    "title": "Projects & Blog",
    "section": "Project 2",
    "text": "Project 2"
  },
  {
    "objectID": "projects.html#project-3",
    "href": "projects.html#project-3",
    "title": "Projects & Blog",
    "section": "Project 3",
    "text": "Project 3"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A bit about me:",
    "section": "",
    "text": "I am an MMA Candidate furthering my Machine Learning skills at Rotman currently.\n\n\n\nCandidate: Masters of Management Analytics at Rotman School of Management\nBachlors of Business Administration at University of Toronto\nUndergraduate Exchange at University of Sydney\n\n\n\n\n\nData Communicator, Freelance\nData Scientist, Indigo Park Canada\nData Scientist, The BRIDGE\nDigital Insights and Data Analyst, Lactalis Canada\nThanks for checking out my web site!"
  },
  {
    "objectID": "index.html#goals",
    "href": "index.html#goals",
    "title": "My Website (WIP)",
    "section": "",
    "text": "Work on Quarto"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "A bit about me:",
    "section": "",
    "text": "Candidate: Masters of Management Analytics at Rotman School of Management\nBachlors of Business Administration at University of Toronto\nUndergraduate Exchange at University of Sydney"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects & Blog",
    "section": "",
    "text": "This project fetches open data to store in a SQLite Database. Since only active registrations are listed, a database tracks status across time. A unique hash is generated for each address, and compares the differentials to update each location accordingly.\nRequests Hashlib SQLite3"
  },
  {
    "objectID": "projects.html#project-1",
    "href": "projects.html#project-1",
    "title": "Projects",
    "section": "",
    "text": "This is project 1"
  },
  {
    "objectID": "newfile.html#backgroundrationale",
    "href": "newfile.html#backgroundrationale",
    "title": "newfiletitle",
    "section": "2.1 Background/rationale",
    "text": "2.1 Background/rationale\n\nExplain the scientific background and rationale for the investigation being reported"
  },
  {
    "objectID": "newfile.html#objectives",
    "href": "newfile.html#objectives",
    "title": "newfiletitle",
    "section": "2.2 Objectives",
    "text": "2.2 Objectives\n\nState specific objectives, including any prespecified hypotheses"
  },
  {
    "objectID": "newfile.html#literature-review",
    "href": "newfile.html#literature-review",
    "title": "newfiletitle",
    "section": "2.3 Literature Review:",
    "text": "2.3 Literature Review:\n\nReview of relevant prior research and theories.\nIdentification of gaps in existing knowledge."
  },
  {
    "objectID": "newfile.html#study-design",
    "href": "newfile.html#study-design",
    "title": "newfiletitle",
    "section": "3.1 Study design",
    "text": "3.1 Study design\n\nPresent key elements of study design early in the paper"
  },
  {
    "objectID": "newfile.html#setting",
    "href": "newfile.html#setting",
    "title": "newfiletitle",
    "section": "3.2 Setting",
    "text": "3.2 Setting\n\nDescribe the setting, locations, and relevant dates, including periods of recruitment, exposure, follow-up, and data collection"
  },
  {
    "objectID": "newfile.html#participants",
    "href": "newfile.html#participants",
    "title": "newfiletitle",
    "section": "3.3 Participants",
    "text": "3.3 Participants\n\nCohort study — Give the eligibility criteria, and the sources and methods of selection of participants. Describe methods of follow-up\nCase-control study — Give the eligibility criteria, and the sources and methods of case ascertainment and control selection. Give the rationale for the choice of cases and controls\nCross-sectional study — Give the eligibility criteria, and the sources and methods of selection of participants\nCohort study — For matched studies, give matching criteria and number of exposed and unexposed\nCase-control study — For matched studies, give matching criteria and the number of controls per case"
  },
  {
    "objectID": "newfile.html#variables",
    "href": "newfile.html#variables",
    "title": "newfiletitle",
    "section": "3.4 Variables",
    "text": "3.4 Variables\n\nClearly define all outcomes, exposures, predictors, potential confounders, and effect modifiers. Give diagnostic criteria, if applicable"
  },
  {
    "objectID": "newfile.html#data-sourcesmeasurement",
    "href": "newfile.html#data-sourcesmeasurement",
    "title": "newfiletitle",
    "section": "3.5 Data sources/measurement",
    "text": "3.5 Data sources/measurement\n\nGive information separately for cases and controls in case-control studies and, if applicable, for exposed and unexposed groups in cohort and cross-sectional studies.\nFor each variable of interest, give sources of data and details of methods of assessment (measurement). Describe comparability of assessment methods if there is more than one group"
  },
  {
    "objectID": "newfile.html#bias",
    "href": "newfile.html#bias",
    "title": "newfiletitle",
    "section": "3.6 Bias",
    "text": "3.6 Bias\n\nDescribe any efforts to address potential sources of bias"
  },
  {
    "objectID": "newfile.html#study-size",
    "href": "newfile.html#study-size",
    "title": "newfiletitle",
    "section": "3.7 Study size",
    "text": "3.7 Study size\n\nExplain how the study size was arrived at"
  },
  {
    "objectID": "newfile.html#quantitative-variables",
    "href": "newfile.html#quantitative-variables",
    "title": "newfiletitle",
    "section": "3.8 Quantitative variables",
    "text": "3.8 Quantitative variables\n\nExplain how quantitative variables were handled in the analyses. If applicable, describe which groupings were chosen and why"
  },
  {
    "objectID": "newfile.html#statistical-methods",
    "href": "newfile.html#statistical-methods",
    "title": "newfiletitle",
    "section": "3.9 Statistical methods",
    "text": "3.9 Statistical methods\n\nDescribe all statistical methods, including those used to control for confounding\nDescribe any methods used to examine subgroups and interactions\nExplain how missing data were addressed\nCohort study — If applicable, explain how loss to follow-up was addressed\nCase-control study — If applicable, explain how matching of cases and controls was addressed\nCross-sectional study — If applicable, describe analytical methods taking account of sampling strategy\nDescribe any sensitivity analyses"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "A bit about me:",
    "section": "",
    "text": "Data Communicator, Freelance\nData Scientist, Indigo Park Canada\nData Scientist, The BRIDGE\nDigital Insights and Data Analyst, Lactalis Canada"
  },
  {
    "objectID": "newproject.html",
    "href": "newproject.html",
    "title": "Latest",
    "section": "",
    "text": "Task orchestration through tools like crontab or Windows Task Scheduler is useful for automating routine processes and managing system tasks.\nThese tools enable users to schedule scripts and other workloads to run automatically at specified times (such as automatic program updates). By automating these tasks, users can ensure critical operations are performed consistently without manual intervention, reducing the risk of human error and freeing up valuable time in both personal and professional environments.\nIn this series, we will use crontab to autorun some scraping scripts\n\n\n\nAutomation Icon"
  },
  {
    "objectID": "newproject.html#project-1",
    "href": "newproject.html#project-1",
    "title": "Projects",
    "section": "",
    "text": "This is project 1"
  },
  {
    "objectID": "newproject.html#project-2",
    "href": "newproject.html#project-2",
    "title": "Projects",
    "section": "Project 2",
    "text": "Project 2"
  },
  {
    "objectID": "newproject.html#project-3",
    "href": "newproject.html#project-3",
    "title": "Projects",
    "section": "Project 3",
    "text": "Project 3"
  },
  {
    "objectID": "newproject.html#chilmark",
    "href": "newproject.html#chilmark",
    "title": "Detailed Project Sample",
    "section": "",
    "text": "Here is a simple image with a description. This also overrides the description position and places it to the left of the image.\n\n\n\nBeach in Chilmark"
  },
  {
    "objectID": "newproject.html#elsewhere",
    "href": "newproject.html#elsewhere",
    "title": "Detailed Project Sample",
    "section": "Elsewhere",
    "text": "Elsewhere\nThe below demonstrates placing more than one image in a gallery. Note the usage of the layout-ncol which arranges the images on the page side by date. Adding the group attribute to the markdown images places the images in a gallery grouped together based upon the group name provided.\n\n\n\n\n\n\n\n\n\nAquinnah\n\n\n\n\n\n\n\nOak Bluffs\n\n\n\n\n\n\n\n\n\nVineyard lighthouse"
  },
  {
    "objectID": "newproject.html#with-computation-code-chunks",
    "href": "newproject.html#with-computation-code-chunks",
    "title": "Latest",
    "section": "With computation code chunks",
    "text": "With computation code chunks\nOptions for lightbox can be passed using chunk options.\n\nplot(1:10, rnorm(10))\n\n\n\n\nSimple demo R plot\n\n\n\n\n\nplot(cars)\n\n\n\n\nPlot about cars data\n\n\n\n\nIt is possible to create several plots, and group them in a lightbox gallery. Use list in YAML for options when you have several plots, on per plot.\n\nplot(mtcars)\n\n\n\n\nCaption for first plot\n\n\n\nplot(cars)\n\n\n\n\nCaption for second plot\n\n\n\n\nWhen lightbox: auto in main YAML config, you can opt-out lightbox on a plot by setting lightbox: false\n\nplot(mtcars)\n\n\n\n\nmtcars"
  },
  {
    "objectID": "newproject.html#credits",
    "href": "newproject.html#credits",
    "title": "Latest",
    "section": "Credits",
    "text": "Credits\nThe images in this example were used under the Unsplash license, view originals below:\n\nChilmark Beach\nAquinnah\nGingerbread House\nEdgartown Light\nEdgartown Sailboat\n\n\n\n\n\nAutomation. credit: Flaticon Pack\n\n\nThe waves break off the coast of Aquinnah on a beautiful summer day.\n\n\nOak Bluffs is famous for its Gingerbread cottages, busy town center, and party like atmosphere.\n\n\nThe Edgartown Lighthouse is a short walk from downtown and has beautiful views over the entrance to Edgartown Harbor.\n\n\nThis is 1 to 10 plot\n\n\nWe see our cars data above\n\n\nThis is the decription for first graph\n\n\nThis is the decription for second graph"
  },
  {
    "objectID": "newproject.html#task-orchestration",
    "href": "newproject.html#task-orchestration",
    "title": "Latest",
    "section": "",
    "text": "Task orchestration through tools like crontab or Windows Task Scheduler is useful for automating routine processes and managing system tasks.\nThese tools enable users to schedule scripts and other workloads to run automatically at specified times (such as automatic program updates). By automating these tasks, users can ensure critical operations are performed consistently without manual intervention, reducing the risk of human error and freeing up valuable time in both personal and professional environments.\nIn this series, we will use crontab to autorun some scraping scripts\n\n\n\nAutomation Icon"
  },
  {
    "objectID": "newproject.html#section",
    "href": "newproject.html#section",
    "title": "Latest",
    "section": "",
    "text": "The below demonstrates placing more than one image in a gallery. Note the usage of the layout-ncol which arranges the images on the page side by date. Adding the group attribute to the markdown images places the images in a gallery grouped together based upon the group name provided.\n\n\n\n\n\n\n\n\n\nAquinnah\n\n\n\n\n\n\n\nOak Bluffs\n\n\n\n\n\n\n\n\n\nVineyard lighthouse"
  },
  {
    "objectID": "newproject.html#for-linux",
    "href": "newproject.html#for-linux",
    "title": "Latest",
    "section": "For Linux",
    "text": "For Linux\nThe below demonstrates placing more than one image in a gallery. Note the usage of the layout-ncol which arranges the images on the page side by date. Adding the group attribute to the markdown images places the images in a gallery grouped together based upon the group name provided."
  },
  {
    "objectID": "newproject.html#for-windows",
    "href": "newproject.html#for-windows",
    "title": "Latest",
    "section": "For Windows",
    "text": "For Windows\n\n\n\n\n\n\n\n\n\nAquinnah\n\n\n\n\n\n\n\nOak Bluffs\n\n\n\n\n\n\n\n\n\nVineyard lighthouse"
  },
  {
    "objectID": "ST_Rental.html",
    "href": "ST_Rental.html",
    "title": "Short Term Rental",
    "section": "",
    "text": "Tracking Airbnb in Toronto using Registration Data\nThe City of Toronto maintains several open datasets related to city operations - updated at a range of frequencies. This project is focused on the Short Term Rental Registration data (updated daily). This data is useful in tracking active Airbnb and similar short term accomodations in Toronto. In order to retrieve insights from these applications, we’d need to gather the data for analysis. However, the data has some limitations - mainly that only active listings are available, not all the historical data.\nPer the given metadata, A short-term rental is all or part of a dwelling unit rented out for less than 28 consecutive days in exchange for payment. Short-term rentals include bed and breakfasts, but exclude hotels, motels, student residences owned or operated by publicly funded or non-profit educational institutions. See the City’s page for more information.\nIn this article, we walk through a practical example of managing and updating a database of short-term rental listings using and SQLite. The goal is to maintain an up-to-date record of rental properties by regularly incorporating new data and updating existing records. Here’s a step-by-step guide on how this can be achieved.\n\nSetting Up the Environment\nPackage Imports: To begin, we import necessary packages including:\n\npandas for data manipulation,\nsqlite3 for database interactions,\nhashlib for hashing, and\na custom script (ShortTermRental) to fetch from Toronto’s Open Data.\n\n2Fetching from Toronto’s Open Data\n\n\nSetting Up the Environment\nTo get started, we need to set up our environment by importing the necessary packages. In this case, we’ll use requests to make API calls, pandas for data manipulation, and datetime to handle date and time information.\nimport requests\nimport pandas as pd\nfrom datetime import datetime, date\n\n\nFetching Rental Data\nThe core of our data process involves an API to retrieve short-term rental data:\n\nDefine the API Endpoint: We first define the base URL for the API provided by the City of Toronto’s open data portal. The endpoint for accessing data packages is constructed as follows:\nbase_url = \"https://ckan0.cf.opendata.inter.prod-toronto.ca\"\nurl = base_url + \"/api/3/action/package_show\"\nparams = { \"id\": \"short-term-rentals-registration\" }\nMake the API Call: We send a GET request using the requests library to the API to retrieve the data package information:\npackage = requests.get(url, params=params).json()\nProcess the Data: The API response contains various resources related to the dataset. We loop through these resources, checking if they are active data stores (datastore_active). For each active resource, we fetch the data in CSV format:\ndf_big = pd.DataFrame()\n\nfor idx, resource in enumerate(package[\"result\"][\"resources\"]):\n    if resource[\"datastore_active\"]:\n        url = base_url + \"/datastore/dump/\" + resource[\"id\"]\n        df_temp = pd.read_csv(url)\n        df_temp['filename'] = url\n        df_temp['first_seen'] = datetime.now().strftime('%Y-%m-%d')\n        df_temp['last_active'] = datetime.now().strftime('%Y-%m-%d')\n        df_big = pd.concat([df_big, df_temp])\nHere’s what each step does:\n\nFetch CSV Data: We build up the URL to access the data dump and read it into a pandas DataFrame.\nAdd Metadata: We include additional columns to keep track of the source URL, the date the data was first seen, and the date it was last active. This will be used later to help track registrations across time, and provide metrics\nConcatenate DataFrames: We combine all the data into a single DataFrame for easier handling.\n\nReturn the Data: Finally, the function returns the combined DataFrame containing all the rental data:\nreturn df_big\n\nThis script provides a streamlined approach to fetching and processing short-term rental data. This method is not only applicable to rental data but can be adapted to various other data sources and types. Feel free to browse Toronto’s Open Data Portal\n\n\nDatabase Setup and Initialization\n\nSQLite Database Creation: We create an SQLite database (ShortTermRental.db) and define a table short_term_rentals to store rental data. The table includes columns for a unique hash, rental details, and date information.\nPopulating Initial Data: Using a CSV file with initial rental data, we calculate the unique hash for each record and insert the data into the short_term_rentals table. This sets up our base dataset.\n\n\n\nHandling New Data\n\nHashing Function: A hash function is used to create a unique identifier for each rental record based on specific columns such as operator_registration_number, address, unit, postal_code, property_type, ward_number, and ward_name. This identifier helps in quickly comparing new records with existing ones to identify updates or new entries.\nCreating Temporary Table: A temporary table (temp_rental) is created to hold new rental data fetched periodically. This table mirrors the structure of the main table but is used to manage and compare new entries.\nFetching and Inserting New Data: New rental data is fetched using the custom script and inserted into the temp_rental table. Hash values are generated for this new data to facilitate efficient comparison with existing records.\nIdentifying New Records: A query is executed to identify records in temp_rental that are not present in short_term_rentals. This helps in pinpointing new listings that need to be added to the main database.\nUpdating the Main Database: New records are appended to the short_term_rentals table. Additionally, the last_active field is updated to reflect the most recent activity date for active listings.\n\n\n\nFinalizing Changes\n\nCommit and Save: Changes are committed to the database to ensure that all updates are saved. The connection to the database is closed to finalize the session.\nExport New Data: A CSV file (new_information_only.csv) is generated to keep a record of newly added entries for further analysis or reporting.\n\n\n\nTesting and Validation\n\nVerification: Various queries are used to verify that the updates and new entries are correctly reflected in the database. This includes checking for records with updated last_active dates and ensuring that the data in short_term_rentals matches expectations.\n\nBy following these steps, we ensure that our rental data remains current and accurate. This approach can be adapted to manage other types of datasets and databases, demonstrating a powerful method for data integration and management using and SQLite."
  },
  {
    "objectID": "ST_Rental.html#task-orchestration",
    "href": "ST_Rental.html#task-orchestration",
    "title": "Latest",
    "section": "",
    "text": "In this article, we walk through a practical example of managing and updating a database of short-term rental listings using Python and SQLite. The goal is to maintain an up-to-date record of rental properties by regularly incorporating new data and updating existing records. Here’s a step-by-step guide on how this can be achieved.\n\n\n\nPackage Imports: To begin, we import necessary Python packages including pandas for data manipulation, sqlite3 for database interactions, hashlib for hashing, and a custom script (ShortTermRental) to fetch new rental data.\nHashing Function: A hash function is used to create a unique identifier for each rental record based on specific columns such as operator_registration_number, address, unit, postal_code, property_type, ward_number, and ward_name. This identifier helps in quickly comparing new records with existing ones to identify updates or new entries.\n\n\n\n\n\nSQLite Database Creation: We create an SQLite database (ShortTermRental.db) and define a table short_term_rentals to store rental data. The table includes columns for a unique hash, rental details, and date information.\nPopulating Initial Data: Using a CSV file with initial rental data, we calculate the unique hash for each record and insert the data into the short_term_rentals table. This sets up our base dataset.\n\n\n\n\n\nCreating Temporary Table: A temporary table (temp_rental) is created to hold new rental data fetched periodically. This table mirrors the structure of the main table but is used to manage and compare new entries.\nFetching and Inserting New Data: New rental data is fetched using the custom script and inserted into the temp_rental table. Hash values are generated for this new data to facilitate efficient comparison with existing records.\nIdentifying New Records: A query is executed to identify records in temp_rental that are not present in short_term_rentals. This helps in pinpointing new listings that need to be added to the main database.\nUpdating the Main Database: New records are appended to the short_term_rentals table. Additionally, the last_active field is updated to reflect the most recent activity date for active listings.\n\n\n\n\n\nCommit and Save: Changes are committed to the database to ensure that all updates are saved. The connection to the database is closed to finalize the session.\nExport New Data: A CSV file (new_information_only.csv) is generated to keep a record of newly added entries for further analysis or reporting.\n\n\n\n\n\nVerification: Various queries are used to verify that the updates and new entries are correctly reflected in the database. This includes checking for records with updated last_active dates and ensuring that the data in short_term_rentals matches expectations.\n\nBy following these steps, we ensure that our rental data remains current and accurate. This approach can be adapted to manage other types of datasets and databases, demonstrating a powerful method for data integration and management using Python and SQLite."
  },
  {
    "objectID": "projects.html#tracking-short-term-rental-in-toronto",
    "href": "projects.html#tracking-short-term-rental-in-toronto",
    "title": "Projects & Blog",
    "section": "",
    "text": "This project fetches open data to store in a SQLite Database. Since only active registrations are listed, a database tracks status across time. A unique hash is generated for each address, and compares the differentials to update each location accordingly.\nRequests Hashlib SQLite3"
  },
  {
    "objectID": "projects.html#basic-task-orchestration",
    "href": "projects.html#basic-task-orchestration",
    "title": "Projects & Blog",
    "section": "Basic Task Orchestration",
    "text": "Basic Task Orchestration\nThis blog walks through script automation using Task Scheduler and Crontab. These tools can programatically run py files, and others - eliminating manual interactions. Naturally, these work as long as the machine is powered, and thus are best suited for remote VMs running 24/7 Crontab Windows Task Scheduler Batch Files"
  },
  {
    "objectID": "projects.html#webscraping-and-accessing-values-from-console",
    "href": "projects.html#webscraping-and-accessing-values-from-console",
    "title": "Projects & Blog",
    "section": "Webscraping and accessing values from console",
    "text": "Webscraping and accessing values from console\nSending AJAX requests to backends may be useful in certain projects, but authentication/bearer/JWT tokens may limit the success of such requests. Thus, this project uses Selenium to simulate a user and extract console values, such as cookies, or bearer tokens.\nSelenium Requests"
  },
  {
    "objectID": "projects.html#stochastic-oscillator",
    "href": "projects.html#stochastic-oscillator",
    "title": "Projects & Blog",
    "section": "Stochastic Oscillator",
    "text": "Stochastic Oscillator\nStochastic Oscilallators are from a family of technical indicators that can be used to infer buy/sell signals. This project pulls TSX data from yfinance, performs the technical analysis and returns a chart of buy and sell signals. As only historical data is used, thus this project serves as a technical showcase, rather than a tool for recommendations\nyfinance Pandas Matplotlib"
  },
  {
    "objectID": "TaskOrchestration.html",
    "href": "TaskOrchestration.html",
    "title": "Task Orchestration",
    "section": "",
    "text": "Task orchestration through tools like Crontab or Windows Task Scheduler is useful for automating routine processes and managing system tasks.\nThese tools enable users to schedule scripts and other workloads to run automatically at specified times (such as automatic program updates). By automating these tasks, users can ensure critical operations are performed consistently without manual intervention, reducing the risk of human error and freeing up valuable time in both personal and professional environments.\nIn this series, we will use crontab to autorun some scraping scripts\n\n\n\nAutomation Icon"
  },
  {
    "objectID": "TaskOrchestration.html#task-orchestration",
    "href": "TaskOrchestration.html#task-orchestration",
    "title": "Task Orchestration",
    "section": "",
    "text": "Task orchestration through tools like Crontab or Windows Task Scheduler is useful for automating routine processes and managing system tasks.\nThese tools enable users to schedule scripts and other workloads to run automatically at specified times (such as automatic program updates). By automating these tasks, users can ensure critical operations are performed consistently without manual intervention, reducing the risk of human error and freeing up valuable time in both personal and professional environments.\nIn this series, we will use crontab to autorun some scraping scripts\n\n\n\nAutomation Icon"
  },
  {
    "objectID": "TaskOrchestration.html#for-linux",
    "href": "TaskOrchestration.html#for-linux",
    "title": "Task Orchestration",
    "section": "For Linux",
    "text": "For Linux\nThe below demonstrates placing more than one image in a gallery. Note the usage of the layout-ncol which arranges the images on the page side by date. Adding the group attribute to the markdown images places the images in a gallery grouped together based upon the group name provided."
  },
  {
    "objectID": "TaskOrchestration.html#for-windows",
    "href": "TaskOrchestration.html#for-windows",
    "title": "Task Orchestration",
    "section": "For Windows",
    "text": "For Windows\n\n\n\n\nAutomation. credit: Flaticon Pack"
  },
  {
    "objectID": "TaskOrchestration.html#with-computation-code-chunks",
    "href": "TaskOrchestration.html#with-computation-code-chunks",
    "title": "Task Orchestration",
    "section": "With computation code chunks",
    "text": "With computation code chunks\nOptions for lightbox can be passed using chunk options.\n\nplot(1:10, rnorm(10))\n\n\n\n\nSimple demo R plot\n\n\n\n\n\nplot(cars)\n\n\n\n\nPlot about cars data\n\n\n\n\nIt is possible to create several plots, and group them in a lightbox gallery. Use list in YAML for options when you have several plots, on per plot.\n\nplot(mtcars)\n\n\n\n\nCaption for first plot\n\n\n\nplot(cars)\n\n\n\n\nCaption for second plot\n\n\n\n\nWhen lightbox: auto in main YAML config, you can opt-out lightbox on a plot by setting lightbox: false\n\nplot(mtcars)\n\n\n\n\nmtcars"
  },
  {
    "objectID": "TaskOrchestration.html#credits",
    "href": "TaskOrchestration.html#credits",
    "title": "Task Orchestration",
    "section": "Credits",
    "text": "Credits\nThe images in this example were used under the Unsplash license, view originals below:\n\nChilmark Beach\nAquinnah\nGingerbread House\nEdgartown Light\nEdgartown Sailboat\n\n\n\n\n\nAutomation. credit: Flaticon Pack\n\n\nThe waves break off the coast of Aquinnah on a beautiful summer day.\n\n\nOak Bluffs is famous for its Gingerbread cottages, busy town center, and party like atmosphere.\n\n\nThe Edgartown Lighthouse is a short walk from downtown and has beautiful views over the entrance to Edgartown Harbor.\n\n\nThis is 1 to 10 plot\n\n\nWe see our cars data above\n\n\nThis is the decription for first graph\n\n\nThis is the decription for second graph"
  },
  {
    "objectID": "projects.html#predicting-e-coli-levels-in-toronto-beaches",
    "href": "projects.html#predicting-e-coli-levels-in-toronto-beaches",
    "title": "Projects & Blog",
    "section": "Predicting E-Coli Levels in Toronto Beaches",
    "text": "Predicting E-Coli Levels in Toronto Beaches\nHigh E-Coli levels in Toronto’s beaches signals that the water is unsafe, and is closed off to the public. This disrupts water activities including local recreation businesses. This project seeks to train a predictive model to identify future high e-coli levels.\nRequests SKLearn Pandas"
  }
]